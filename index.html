<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="description"
        content="Personalized Image Editing in Text-to-Image Diffusion Models via Collaborative Direct Preference Optimization">
        <meta name="keywords" content="Diffusion Models, Datasets">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="icon" type="image/png" sizes="32x32" href="./static/favico.png">
        <!-- <script src="https://www.w3counter.com/tracker.js?id=151390"></script> -->
        <title>Personalized Image Editing</title>
        <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
        dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
        </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    </head>

    <body>

      <section class="hero">
        <div class="hero-body">
          <div class="container is-max-desktop">
            <div class="columns is-centered">
              <div class="column has-text-centered">
                <h1 class="title is-1 publication-title">Personalized Image Editing in Text-to-Image Diffusion Models via Collaborative Direct Preference Optimization</h1>
                <div class="is-size-5 publication-authors">
                  <span class="author-block">
                    <a href="">Connor Dunlop</a>,</span>
                  <span class="author-block">
                    <a href="https://sanghani.cs.vt.edu/person/matthew-zheng/">Matthew Zheng</a>,</span>
                  <span class="author-block">
                    <a href="https://sites.google.com/view/hidir-yesiltepe">Kavana Venkatesh</a>,</span>
                  <span class="author-block">
                    <a href="https://federicotombari.github.io/">Pinar Yanardag</a>,</span>
                  </span>
                </div>
      
                <div class="is-size-5 publication-authors">
                  <span class="author-block">Virginia Tech</span>
                  <!-- <span class="author-block"><sup>2</sup>ETH Zurich</span>
                  <span class="author-block"><sup>3</sup>TUM</span>
                  <span class="author-block"><sup>4</sup>Google</span>
                  <span class="author-block"><sup>5</sup>Artbreeder</span> -->
                </div>
<!--                 
                <div class="is-size-8 publication-authors">
                  <span class="author-block"><sup>*</sup>Joint co-author</span>
                </div> -->
      
                <div class="column has-text-centered">
                  <div class="publication-links">
                    <!-- PDF Link. -->
                    <span class="link-block">
                      <a href=""
                         class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                            <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
                    <!-- <span class="link-block">
                      <a href="https://huggingface.co/datasets/stylebreeder/stylebreeder"
                         class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                            &#129303;
                        </span>
                        <span>Dataset</span>
                      </a>
                    </span> -->
                    <!-- Code Link. -->
                    <span class="link-block">
                      <a href=""
                         class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                            <i class="fab fa-github"></i>
                        </span>
                        <span>Code (Coming Soon)</span>
                        </a>
                    </span>
                    <!-- Dataset Link. -->
                    <!-- <span class="link-block">
                      <a href="https://github.com/google/nerfies/releases/tag/0.1"
                         class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                            <i class="far fa-images"></i>
                        </span>
                        <span>Data</span>
                        </a> -->
                  </div>
      
                </div>
              </div>
            </div>
          </div>
        </div>
      </section>

      <!-- <section class="hero teaser">
        <div class="container is-max-desktop">
          <div class="hero-body">
            <h4 class="subtitle">
                <b>TL;DR</b> We introduce a new extensive dataset from Artbreeder on CC0 license, capturing millions of
                 user-generated images and styles. We cluster images based on their stylistic similarities, helping to map 
                 out the landscape of user-generated art.
                 Utilizing historical data of the users, we showcase a recommendation system that aligns style suggestions with 
                 individual preferences. We release a web-based platform, Style Atlas, providing public access to download 
                 pre-trained style LoRAs.
        </div>
      </section> -->


      <div class="container">
        <figure class="image" style="max-width:70%; margin: 0 auto;">
          <img src="./static/images/teaser-pers.png" />
          <br>
          <figcaption>
            Our framework performs personalized image editing aligned with user's preference via
          a novel DPO objective that learns user preferences while leveraging collaborative signals from
          like-minded individuals.
          </figcaption>
        </figure>
        <br />
      </div>

      <section class="section">
        <div class="container is-max-desktop">
          <!-- Abstract. -->
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title is-3">Abstract</h2>
              <div class="content has-text-justified">
                <p>
                    Text-to-image (T2I) diffusion models have made remarkable strides in generating
                    and editing high-fidelity images from text. Yet, these models remain fundamentally
                    generic, failing to adapt to the nuanced aesthetic preferences of individual users. In
                    this work, we present the first framework for personalized image editing in diffusion
                    models, introducing Collaborative Direct Preference Optimization (C-DPO), a
                    novel method that aligns image edits with user-specific preferences while leveraging
                    collaborative signals from like-minded individuals. Our approach encodes each user
                    as a node in a dynamic preference graph and learns embeddings via a lightweight
                    graph neural network, enabling information sharing across users with overlapping
                    visual tastes. We enhance a diffusion model's editing capabilities by integrating
                    these personalized embeddings into a novel DPO objective, which jointly optimizes
                    for individual alignment and neighborhood coherence. Comprehensive experiments,
                    including user studies and quantitative benchmarks, demonstrate that our method
                    consistently outperforms baselines in generating edits that are aligned with user
                    preferences.
                </p>
              </div>
            </div>
          </div>
        </section>
          <!--/ Abstract. -->
      
        
        <!-- Method -->
        <section class="section">
          <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
              <div class="column is-12">
                <h2 class="title is-3">Method Overview</h2>
      
                <div class="content has-text-justified">
                  <!--
                  <p>
                    Explain method
                  </p>
                -->
                  <div class="container">
                    <img src="./static/images/framework.png" />
                    <br />
                  </div>
                  <p>
                    1) We first fine-tune a language model so it can generate precise editing instructions. 2) We
                      then introduce a graph-aware DPO objective that leverages collaborative user data to learn individual
                      editing preferences. 3) After training, the system takes an input image and a user profile, produces
                      tailored editing instructions, and outputs the corresponding personalized edit.
                  </p>
                </div>
              </div>
            </div>
          </div>

        <!--/ Method -->
 

            <!-- Personalized Generation -->
            <section class="section">
            <div class="container is-max-desktop">
              <div class="columns is-centered has-text-centered">
                <div class="column is-12">
                  <h2 class="title is-3">Personalized Image Editing Based on User Preferences</h2>
        
                  <div class="content has-text-justified">
                    <!--
                    <p>
                      Explain method
                    </p>
                  -->
                    <div class="container">
                      <img src="./static/images/qual.png" />
                      <br />
                    </div>
                    <p>
                       <b>(a) Qualitative Results for Individual Users on Different Objects.</b> Our framework is able
                          to incorporate personalized elements into the image editing process, such as adding neon or futuristic
                          elements for Futuristic Techie profile. <b>(b) Qualitative Results for User-Provided Personalized
                          Edits.</b> Our framework allows users to provide additional guidance while performing personalized
                          edits.
                    </p>

                    <div class="container">
                      <img src="./static/images/same-user.png" />
                      <br />
                    </div>

                    <p>
                      <b>Qualitative Results for a Single User on Diverse Objects.</b> For a user who loves unicorns,
                    rainbows, and vibrant, playful palettes, our system infuses that whimsical aesthetic into a wide range
                    of objects - from cars and guitars to watchtowers.
                    </p>
                  </div>
                </div>
              </div>
            </div>
          </section>
          <!-- Personalized Generation -->
          
          <!-- Recommendation -->

          <!-- Recommendation -->

          <!-- BibTeX -->
          <!-- <section class="section" id="BibTeX">
            <div class="container is-max-desktop content">
              <h2 class="title">BibTeX</h2>
              <pre><code>@inproceedings{
    zheng2024stylebreeder,
    title={Stylebreeder: Exploring and Democratizing Artistic Styles through Text-to-Image Models},
    author={Matthew Zheng and Enis Simsar and Hidir Yesiltepe and Federico Tombari and Joel Simon and Pinar Yanardag},
    booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
    year={2024},
    url={https://openreview.net/forum?id=EvgyfFsv0w}
}</code></pre>
            </div>
          </section> -->
          
          <footer class="footer">
            <div class="container">
              <div class="content has-text-centered is-centered">
                <a class="icon-link" href="https://github.com/stylebreeder" class="external-link" disabled>
                  <i class="fab fa-github"></i>
                </a>
              </div>
              <div class="columns">
                <div class="column is-8">
                  <div class="content has-text-justified">
                    <!-- <p>
                      This website is licensed under a <a rel="license"
                                                          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                      Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p> -->
                    <p>This page is adapted from <a
                        href="https://github.com/nerfies/nerfies.github.io">this</a> implementation.
                    </p>
                  </div>
                </div>
              </div>
            </div>
          </footer>
    </body>
</html>
